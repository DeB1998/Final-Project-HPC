\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multicol}
\usepackage{geometry}
\usepackage{float}
\usepackage[unicode=true, psdextra]{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{expl3}
\usepackage{xparse}
\usepackage{array}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage[table, svgnames]{xcolor}
\usepackage{csquotes}
\usepackage{titling}
\usepackage{enumitem}
\usepackage{comment}
\usepackage{lipsum}
\usepackage{bm}
\usepackage{mathtools}
\usepackage{titlesec}
\usepackage{tikz}
\usepackage{color}

% https://tex.stackexchange.com/questions/88929/vertical-table-lines-are-discontinuous-with-booktabs

\setlength{\droptitle}{-2.75em} %-5em
\geometry{left=1cm,right=1cm,top=1.8cm,bottom=2cm}
\graphicspath{{images/}}
\captionsetup[table]{skip=5pt}
\titlespacing*{\section}{0pt}{5pt}{5pt}
\titlespacing*{\subsection}{0pt}{5pt}{5pt}
\titlespacing*{\subsubsection}{0pt}{5pt}{5pt}

\hypersetup{
    pdftitle={Parallelization of the SLINK clustering algorithm},
    pdfauthor={Alessio De Biasi (870288); Jonathan Gobbo (870506)},
    hidelinks,
    pdfcreator={XeLaTeX}}

\title{Parallelization of the SLINK clustering algorithm\vspace{-1.25ex}}
\author{Alessio De Biasi (870288) \and Jonathan Gobbo (870506)}
\date{August 2022}

% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}

\newenvironment{tablelayout}[1][]{
    \begin{table}[H]
        \centering
        \caption{#1}
        \begin{tabular}[H]{ccccccc}
            \hline
            & s1 & s2 & s3 & s4 & tot & \\
            \hline
            }{
            \\
            \hline
        \end{tabular}
    \end{table}
}

\newenvironment{tablelayout2}{
    \begin{table}[H]
        \centering
        \begin{tabular}[H]{lrrrrrr}
            \hline
            DS & \centering s1 & \centering s2 & \centering s3 & s4 & s5 & tot \\
            \hline
            }{
            \\
            \hline
        \end{tabular}
    \end{table}
}

\ExplSyntaxOn
\NewDocumentCommand{\formatNumber}{mm} {
\seq_set_split:Nnn \values {.} {#1}
\seq_item:Nn \values {1}
\int_compare:nNnTF{\seq_count:N \values} = {2}
    {.\footnotesize    \seq_item:Nn \values {2}}
    {}
\normalsize$\,$#2
}
\NewDocumentEnvironment{tableLayout}{mb}{
\setlength\intextsep{2mm}
\renewcommand{\divisor}{\midrule}
\seq_set_split:Nnn \l_rows_seq { \\ } {#2}
\begin{table}[H]
\centering
\begin{tabularx}{0.98\linewidth}[H]{
>{\raggedright}p{1.8em}|
%!{\color{Gainsboro!50!Lavender}\vline width 0.75em}
>{\raggedleft}X
>{\raggedleft}X
>{\raggedleft}X
>{\raggedleft}X
>{\raggedleft\arraybackslash}X
}
\toprule
\textbf{DS} &
\multicolumn{1}{c}{\hspace{1.2em}\textbf{S1}} &
\multicolumn{1}{c}{\textbf{S2}} &
\multicolumn{1}{c}{\textbf{S3}} &
\multicolumn{1}{c}{\textbf{S4}} &
\multicolumn{1}{c}{\textbf{Total}} \\
\toprule
\seq_use:Nn \l_rows_seq {\\}\\
\bottomrule
\end{tabularx}
\caption{#1}
\end{table}
}{}

\NewDocumentEnvironment{tableLayout2}{mb}{
\setlength\intextsep{2mm}
\renewcommand{\divisor}{\midrule}
\seq_set_split:Nnn \l_rows_seq { \\ } {#2}
\begin{table}[h]
\centering
\begin{tabularx}{0.98\linewidth}[h]{
>{\raggedright}p{1.8em}|
%!{\color{Gainsboro!50!Lavender}\vline width 0.75em}
>{\raggedleft}p{1.8em}
>{\raggedleft}X
>{\raggedleft}X
>{\raggedleft}X
>{\raggedleft}X
>{\raggedleft\arraybackslash}p{3.2em}
}
\toprule
\textbf{DS} &
\multicolumn{1}{c}{\hspace{0.4em}\textbf{S1}} &
\multicolumn{1}{c}{\textbf{S2}} &
\multicolumn{1}{c}{\textbf{S3}} &
\multicolumn{1}{c}{\textbf{S4}} &
\multicolumn{1}{c}{\textbf{S5}} &
\multicolumn{1}{c}{\textbf{Total}} \\
\toprule
\seq_use:Nn \l_rows_seq {\\}\\
\bottomrule
\end{tabularx}
\caption{#1}
\end{table}
}{\vspace{-4pt}}
\ExplSyntaxOff

\newcommand{\divisor}{& \\[-2.25ex]\hline& \\[-2.25ex]}
\newcommand{\s}{$\,$s}
\newcommand{\ms}{$\,$ms}
\newcommand{\m}{$\,$m$\ $}

\setlength{\itemsep}{0pt}
\setlength{\parskip}{0pt}
\setlist{itemsep=0.25mm,
% Margin of the whole list
topsep=0.25mm,
% Padding between each element of the list
parsep=0.25mm}

\begin{document}
\twocolumn
\maketitle

\section{Introduction}

The purpose of this project is to implement the SLINK clustering algorithm and to apply
parallelization techniques to improve its performance.

All the implementations of the clustering algorithms are written in \texttt{C++20} and they are
compiled with the GCC G++ 12.1.1 (Red Hat) compiler, using the \texttt{-O3} and
\texttt{-march=native} flags.

In particular, we tested the clustering algorithm implementations on two datasets:
\begin{itemize}
\item Accelerometer\footnote{https://archive.ics.uci.edu/ml/datasets/Accelerometer} (A), composed
of 153'000 samples, each of which with 5 attributes. For the tests we have performed, we have
selected only the last 3 of them;
\item Generated (G), composed of 100'000 samples, each of which with 45 randomly generated real
attributes uniformly distributed in the range 0-100.
\end{itemize}

We will report the mean execution time of 3 executions of each implementation on the two datasets,
run on a machine equipped with an AMD Ryzen 7 1700 CPU with 8 cores and 16 threads, 16 GB of RAM,
and running Fedora Workstation 36.
In particular, we measured the time taken by each step of the pseudo-code (reported as S1, S2, S3
and S4) to be executed.

In all the tests we used a \texttt{std::vector} to hold the values of $\pi$ and $\lambda$.

Note that the reported total times include also some extra time spent by the various
implementations to perform operations like allocating and de-allocating the memory, or copying
the iterators.

Moreover, for space reasons, in some tests we do not report the results obtained using 2 and 16
threads

\hypertarget{implementations}{
\section{Implementations}
\label{implementations}}

\hypertarget{sequential}{
\subsection{Sequential}
\label{sequential}}

We first implemented the sequential version of the clustering algorithm.
This implementation is just the translation in \texttt{C++} code of the pseudo-code reported in
the slides.

Data is supplied as a
\texttt{std::vector\textless{}double\ *\textgreater{}}, i.e., a vector
of pointers to heap-allocated arrays, where each of these arrays holds the attributes of one data
sample.

\begin{tableLayout}{Execution times of the sequential implementation}
A & 19\ms & 1\m 30\s & \formatNumber{37.330}{s} & \formatNumber{20.271}{s} & 2\m 28\s \\
\divisor
G & 19\ms & 8\m 59\s & \formatNumber{16.246}{s} & \formatNumber{12.802}{s} & 9\m 28\s
\end{tableLayout}


\hypertarget{parallel-distance}{%
\subsection{Multithreaded distance computation}\label{parallel-distance}}

From the previous tests results, we saw that he computation of the distances is the step of the
algorithm taking most of the time to be executed.

Since each distance can be computed independently from the others, their computation can be
easily made parallel by using the \emph{OpenMP} library.

The supplied data has the same memory layout as before.

\begin{tableLayout}{Execution times of the first parallel implementation}
A2 & 10\ms & \formatNumber{43.043}{s} & \formatNumber{39.568}{s} & \formatNumber{23.286}{s} & 1\m
46\s \\
A4 & 11\ms & \formatNumber{29.641}{s} & \formatNumber{36.144}{s} & \formatNumber{23.609}{s} & 1\m
29\s \\
A8 & 11\ms & \formatNumber{20.940}{s} & \formatNumber{35.260}{s} & \formatNumber{23.541}{s} & 1\m
20\s \\
A12 & 10\ms & \formatNumber{24.402}{s} & \formatNumber{36.713}{s} & \formatNumber{24.204}{s} &
1\m 25s \\
A16 & 11\ms & \formatNumber{27.201}{s} & \formatNumber{47.172}{s} & \formatNumber{26.257}{s} &
1\m 41\s \\
\divisor
G2 & 13\ms & 4\m 12\s & \formatNumber{15.228}{s} & \formatNumber{13.855}{s} & 4\m 41\s \\
G4 & 15\ms & 2\m 23\s & \formatNumber{15.555}{s} & \formatNumber{14.881}{s} & 2\m 53\s \\
G8 & 14\ms & 1\m 34\s & \formatNumber{15.305}{s} & \formatNumber{14.977}{s} & 2\m 04\s \\
G12 & 12\ms & 1\m 43\s & \formatNumber{17.569}{s} & \formatNumber{15.308}{s} & 2\m 16\s \\
G16 & 12\ms & 1\m 42\s & \formatNumber{20.592}{s} & \formatNumber{15.668}{s} & 2\m 18\s
\end{tableLayout}

\hypertarget{parallel-sse-avx}{%
\subsection{SSE and AVX in the computation of the distances}\label{parallel-sse-avx}}

Since the attributes of the data samples to cluster are stored contiguously in memory, we decided
to improve the previous solution using the SSE and AVX instructions when computing the distances.

Indeed, to compute the distance between two points, the algorithm perform the same instructions
(difference and square) to every pair of attributes.

\begin{tableLayout}{Execution times of the implementation using SSE}
A2 & 11\ms & \formatNumber{46.922}{s} & \formatNumber{32.362}{s} & \formatNumber{21.116}{s} & 1\m
40\s \\
A4 & 11\ms & \formatNumber{34.329}{s} & \formatNumber{35.250}{s} & \formatNumber{23.791}{s} & 1\m
33\s \\
A8 & 9\ms & \formatNumber{27.252}{s} & \formatNumber{35.007}{s} & \formatNumber{23.633}{s} & 1\m
26\s \\
A12 & 10\ms & \formatNumber{27.328}{s} & \formatNumber{37.252}{s} & \formatNumber{24.346}{s} &
1\m 29\s \\
A16 & 12\ms & \formatNumber{28.596}{s} & \formatNumber{47.285}{s} & \formatNumber{26.313}{s} &
1\m 42\s \\
\divisor
G2 & 14\ms & 4\m 29\s & \formatNumber{16.732}{s} & \formatNumber{14.733}{s} & 5\m 00\s \\
G4 & 15\ms & 2\m 33\s & \formatNumber{19.175}{s} & \formatNumber{16.085}{s} & 3\m 08\s \\
G8 & 13\ms & 1\m 39\s & \formatNumber{19.319}{s} & \formatNumber{15.894}{s} & 2\m 15\s \\
G12 & 13\ms & 1\m 43\s & \formatNumber{18.766}{s} & \formatNumber{15.457}{s} & 2\m 18\s \\
G16 & 14\ms & 1\m 39\s & \formatNumber{21.918}{s} & \formatNumber{15.986}{s} & 2\m 17\s
\end{tableLayout}

\begin{tableLayout}{Execution times of the implementation using AVX}
A2 & 8\ms & \formatNumber{39.106}{s} & \formatNumber{38.321}{s} & \formatNumber{23.127}{s} & 1\m
41\s \\
A4 & 10\ms & \formatNumber{24.656}{s} & \formatNumber{37.981}{s} & \formatNumber{23.659}{s} & 1\m
26\s \\
A8 & 8\ms & \formatNumber{17.814}{s} & \formatNumber{37.826}{s} & \formatNumber{23.772}{s} & 1\m
19\s \\
A12 & 8\ms & \formatNumber{18.416}{s} & \formatNumber{40.067}{s} & \formatNumber{24.198}{s} & 1\m
23\s \\
A16 & 10\ms & \formatNumber{19.824}{s} & \formatNumber{52.452}{s} & \formatNumber{26.367}{s} &
1\m 39\s \\
\divisor
G2 & 13\ms & 4\m 34\s & \formatNumber{14.860}{s} & \formatNumber{14.236}{s} & 5\m 03\s \\
G4 & 15\ms & 2\m 37\s & \formatNumber{15.111}{s} & \formatNumber{15.457}{s} & 3\m 07\s \\
G8 & 14\ms & 1\m 42\s & \formatNumber{15.143}{s} & \formatNumber{15.660}{s} & 2\m 13\s  \\
G12 & 14\ms & 1\m 49\s & \formatNumber{17.418}{s} & \formatNumber{15.516}{s} & 2\m 22\s \\
G16 & 14\ms & 1\m 44\s & \formatNumber{20.112}{s} & \formatNumber{15.970}{s} & 2\m 20\s
\end{tableLayout}

We expected this implementation to work faster than the previous one but, as the results show,
this implementation works slightly slower than the previous one.

Investigating using the \textit{perf} tool, we discovered that most of the time the CPU is
stalled due to a high rate of cache misses (about 80\% of all the data memory accesses).

\hypertarget{a-new-data-structure}{%
\subsection{A new data structure}\label{a-new-data-structure}}

Therefore, we decided to change the data structure holding the data samples to cluster in flavour
to a more a contiguous one.

In particular, we chose to organize the data as a unique heap-allocated array, where the data
samples are stored one after the other, like the attributes of each sample.

\begin{tableLayout}{Execution times of the implementation using a contiguous data structure and
SSE (2 and 16 threads tests omitted)}
A4 & 4\ms & \formatNumber{11.770}{s} & \formatNumber{34.453}{s} & \formatNumber{23.509}{s} & 1\m
10\s \\
A8 & 4\ms & \formatNumber{7.531}{s} & \formatNumber{35.604}{s} & \formatNumber{23.674}{s} & 1\m
07\s \\
A12 & 4\ms & \formatNumber{8.277}{s} & \formatNumber{37.068}{s} & \formatNumber{24.300}{s} & 1\m
10\s \\
\divisor
G4 & 9\ms & \formatNumber{44.391}{s} & \formatNumber{14.319}{s} & \formatNumber{15.880}{s} & 1\m
15\s \\
G8 & 8\ms & \formatNumber{37.005}{s} & \formatNumber{14.162}{s} & \formatNumber{15.937}{s} & 1\m
07\s \\
G12 & 8\ms & \formatNumber{37.132}{s} & \formatNumber{15.271}{s} & \formatNumber{15.902}{s} & 1\m
08\s
\end{tableLayout}

\begin{tableLayout}{Execution times of the implementation using a contiguous data structure and
AVX(2 and 16 threads tests omitted)}
A4 & 4\ms & \formatNumber{12.462}{s} & \formatNumber{42.709}{s} & \formatNumber{23.633}{s} & 1\m
18\s \\
A8 & 4\ms & \formatNumber{8.315}{s} & \formatNumber{42.649}{s} & \formatNumber{23.517}{s} & 1\m
14\s \\
A12 & 4\ms & \formatNumber{8.368}{s} & \formatNumber{42.744}{s} & \formatNumber{23.809}{s} & 1\m
15\s \\
\divisor
G4 & 10\ms & \formatNumber{46.830}{s} & \formatNumber{14.452}{s} & \formatNumber{15.770}{s} & 1\m
17\s \\
G8 & 8\ms & \formatNumber{38.992}{s} & \formatNumber{14.454}{s} & \formatNumber{16.222}{s} & 1\m
10\s \\
G12 & 8\ms & \formatNumber{39.331}{s} & \formatNumber{15.580}{s} & \formatNumber{15.969}{s} & 1\m
11\s
\end{tableLayout}

As we can see form these results, making the data samples contiguous in memory improves
significantly the performance of the algorithm.

Indeed, when a thread loads one data sample, it is very likely that with the same memory
transaction more data samples are brought to the cache, hence, when the thread analyzes the
following data sample, it is already in cache.

\hypertarget{stage-3-parallel}{
\subsection{Make the insertion of a new point parallel}
\label{stage-3-parallel}}

After having made parallel the computation of the distances, we focused on making parallel the other
step of the algorithm takes most of the time to complete, i.e., the insertion of a new point to
the dendrogram (i.e., the step \textit{3} of the pseudo-code).

However, there is no chance to make it parallel because, when the element at index $i$ is
analyzed, the algorithm requires that all the elements before have already been analyzed.

Therefore, if we give each thread an element to analyze in a round-robin fashion, then there will
be always a thread working while all the other threads will be blocked waiting for the active
thread to complete its work.

\hypertarget{stage-4-parallel}{
\subsection{Make the rearrangement of the structure of the dendrogram parallel}
\label{stage-4-parallel}}

Therefore, we decided to try to make parallel the third step of the algorithm that takes a
significant amount of time to be executed, i.e., the rearrangement of the structure of the
dendrogram after a new point has been added (i.e., the step \textit{4} of the pseudo-code).

Since each iteration of the \texttt{for} loop is independent from the others, making it parallel
it is almost trivial by using the \emph{OpenMP} library.

Like the last implementation, data is supplied as a unique heap-allocated array.

For space reasons, we omitted the results of the implementation when using SSE, since its
execution times that are slightly bigger than the ones of AVX.

\begin{tableLayout}{Execution times of the implementation executing in parallel the computation
of the distance (using threads and AVX instructions) as well as the rearrangement of the
structure of the dendrogram (2 and 16 threads tests omitted)}
A4 & 4\ms & \formatNumber{10.599}{s} & \formatNumber{42.538}{s} & \formatNumber{8.939}{s} & 1\m
02\s \\
A8 & 4\ms & \formatNumber{5.836}{s} & \formatNumber{43.255}{s} & \formatNumber{5.659}{s} &
\formatNumber{54.760}{s} \\
A12 & 4\ms & \formatNumber{6.895}{s} & \formatNumber{45.326}{s} & \formatNumber{4.489}{s} &
\formatNumber{56.720}{s} \\
\divisor
G4 & 9\ms & \formatNumber{46.341}{s} & \formatNumber{15.961}{s} & \formatNumber{6.888}{s} & 1\m
09\s \\
G8 & 8\ms & \formatNumber{38.337}{s} & \formatNumber{16.110}{s} & \formatNumber{3.792}{s} &
\formatNumber{58.254}{s} \\
G12 & 8\ms & \formatNumber{39.039}{s} & \formatNumber{17.603}{s} & \formatNumber{3.408}{s} & 1\m
00\s
\end{tableLayout}

\vspace{-10pt}

\hypertarget{failed-attempt}{
\subsection{Devising a new algorithm}
\label{failed-attempt}}

As shown by the results, even if we make the initialization of $\pi$ and $\lambda$ parallel (i.e
., the step \textit{1} of the pseudo-code), we can gain only few milliseconds.

Therefore, to improve the performance, we tried to devise a new algorithm. This new algorithm
builds incrementally the dendrogram like the pseudo-code, but in a different way.

In particular, when this new algorithm adds to the dendrogram a new the data sample $d$, it first
computes the closest data sample $c$ that has already added.

Since any cluster containing $d$ must also contain $c$ (otherwise $c$ is not the closest data
sample to $d$), the algorithm adds a new edge connecting $d$ to an existent cluster containing $c$.

To do so, the algorithm traverses the path from the leaf
representing the data sample $c$ to the root of the dendrogram until it finds the last edge
$\varepsilon$ with height smaller than the distance between $d$ and $c$.
The algorithm, then, connects the edge $\varepsilon$ with the new edge, and the new edge with the
parent of $\varepsilon$.

Then, the algorithm continues traversing the path so to possibly update the height of all the
remaining edges.

Indeed, since we have added the data sample $d$ to the dendrogram, the distances between the
any super-cluster containing both $c$ and $d$ and the cluster it joins may have changed.
However, since the heights of any of such edges can't get smaller than the heights of
their children, the structure of the dendrogram will not change.

The algorithm can be easily made parallel if we represent the dendrogram as a binary tree with a
linked structure where each node stores a pointer to the parent node together with some other
information.

If we assign to each thread a node of the path from $c$ to the root of the
dendrogram, one of these threads will take care of adding the new edge, while all the others will
take care of updating the heights of the edges.
Since the operations performed by the threads are almost independent, we require very little
synchronization.

However, there are some cases in which this algorithm does not work.
For instance, suppose that a cluster $\{a, b\}$ joins another cluster $\{c, d\}$.
Suppose also that the new data sample $e$ is closer to $b$, and suppose that $a$ is closer to $b$
more than to $c$.

In this case, the algorithm, will create an edge joining the cluster $\{a, b\}$ and the data sample
$e$. However, $c$ may become closer to the resulting cluster $\{a, b, e\}$ than to $d$. This
implies that $c$ will not be connected directly to $d$, hence the dendrogram must be rearranged.

In general, the entire structure of the dendrogram may change, hence the threads do not
work on independent data anymore.
This, therefore, will require much more synchronization, which may force the threads to be
executed sequentially, hence reducing the performances.
Moreover, we also require each node of the dendrogram to store much more information.

Therefore, we abandoned this algorithm, and we tried some micro-optimizations to the algorithm we
have used so far.

%
%
%

\begin{comment}
To overcome the impossibility of parallelize the step \textit{3} of the algorithm, we decided to
devise a new algorithm, which can be made parallel more easily.

This new algorithm builds incrementally the dendrogram like the algorithm we used so far, but it
is based on a different but simple idea.

Suppose the algorithm needs to add to the dendrogram a new data sample $d$ and suppose that, among
all the samples already added to the dendrogram, the data sample $c$ is the closest one with
distance $l$ (i.e., $c$ is the data sample with the minimum distance from $d$).

Then, any cluster containing $d$ for sure contains also $c$, otherwise there would be another
data sample $e$ already added to the dendrogram which is closer to $d$ more than $c$, but we assumed
$c$ is the closest one.

If we look at the structure of the dendrogram, this consideration implies that the new data sample
$d$ is connected to one of the edges in the path from $c$ to the root of the dendrogram.

\begin{figure}[H]
\centering
\begin{subfigure}{.5\linewidth}
\includegraphics[width=\linewidth]{graph-2}
\caption{Graph with all the points, $F$ is the next point to add}
\end{subfigure}%
\begin{subfigure}{.5\linewidth}
\includegraphics[width=\linewidth]{dendrogram-2}
\caption{Dendrogram}
\end{subfigure}
\caption{Situation}
\end{figure}

In particular, the new edge will be added on that path right before the first edge $\varepsilon$
with an
height that is bigger than $l$.

Therefore, adding a new edge to the dendrogram is trivial if we represent the dendrogram as a
binary tree, where:
\begin{itemize}
\item Each leaf stores the identifier of the data sample and a pointer to the parent node;
\item Each internal node stores the pointer to the parent node and the children nodes, as
well as the value of height of the edge.
\end{itemize}
Indeed, it is just a matter of changing the values of two pointers, namely the pointer to the
left or right child of the node representing the edge $\varepsilon$, and the pointer to the
parent node of the node that was previously connected to $\varepsilon$.

However, this is only half of the work. Suppose, at some point, the cluster $X$ joins cluster $Y$
at distance $k$. Suppose that $c$ belongs to $X$ and suppose that $k > l$.

This implies that $X$ must also contain $d$ because, since $c$ belongs to $X$, then one of the
sub-clusters of $X$ containing $c$ must join the data sample $d$, since the distance between $c$
and $d$ is smaller than $k$.

However, if $X$ joined $Y$ at distance $k$ before adding $d$, now that we have added $d$ the two
clusters may have become closer.

If we look at the dendrogram, this may require to change the heights of all the edges in the path
from the newly added edge to the root of the dendrogram.
Note that, in any case, the heights of any of such edges can't get smaller than the heights of
their children.

Therefore, if in the nodes representing the dendrogram we store also the information about which
point of the left sub-tree is the closest to which point of the right sub-tree, then adjusting
the heights stored in such nodes is trivial.

Indeed, suppose that the node stores the information that the two closest data samples are $e$
and $f$. Suppose also that $d$ belongs to a cluster that also contain $e$. Then, to update the
height of the edge we need to to check if the distance between $d$ and $f$ is smaller than the
distance between $e$ and $f$ (which is the current height of the edge). If so, we need to update
the height of the edge as well as the two closest points (which will be $d$ and $f$). Otherwise,
no change is made.

All of these operations can be easily made parallel. We just need to assign to each thread an
node of the path from $c$ to the root of the dendrogram in a round-robin fashion. The given node
can represent:
\begin{enumerate}
\item An edge with height smaller than $l$. In this case, the thread just does nothing and
selects another edge;

\item The first edge in the path with an height larger than $l$. This can be easily tested
by looking at the heights of the two children, if at least one of them is not a leaf. If they
are both a leaves, then the edge receives by the thread IS the first in the path with an
height larger than $l$.

In this case, the thread just changes the values some the pointers,
which can be done safely by using the \textit{Compare And Swap} primitives offered by the CPU.

\item An edge that does not fall in one of the previous cases. Therefore, the thread needs
only to update the height stored in the node and the two closest points, if the newly added
data sample has made two two sub-clusters closer.
\end{enumerate}

This algorithm is extremely parallel because there almost no data dependency among the nodes the
threads analyze.

However, there are some cases in which this algorithm does not work. Let's take the following
example:

\begin{figure}[H]
\centering
\begin{subfigure}{.5\linewidth}
\includegraphics[width=\linewidth]{graph-2}
\caption{Graph with all the points, $F$ is the next point to add}
\end{subfigure}%
\begin{subfigure}{.5\linewidth}
\includegraphics[width=\linewidth]{dendrogram-2}
\caption{Dendrogram}
\end{subfigure}
\caption{Situation}
\end{figure}

When we add to the the dendrogram the point $F$, its structure completely changes:

\begin{figure}[H]
\centering
\begin{subfigure}{.5\linewidth}
\includegraphics[width=\linewidth]{graph-3}
\caption{Graph with all the points, $F$ is the last added point}
\end{subfigure}%
\begin{subfigure}{.5\linewidth}
\includegraphics[width=\linewidth]{dendrogram-3}
\caption{Dendrogram}
\end{subfigure}
\caption{Situation}
\end{figure}

This implies that any node of the tree representing the dendrogram can be moved, which implies
that the pointers to the parent and children nodes can change on every node.

Since the threads are traversing the path from a leaf to the root, if a thread moves a node, it
must perform such an operation in mutual exclusion, otherwise the other threads may analyze nodes
that do not belong to the path.

This requires any thread to lock the node they are using, so to prevent any other thread to
traverse the node and analyze the parent of such node, which indeed may change is the thread
moves the node.

All these locks will introduce a high complexity in the algorithm, which leads to poor performances.

Therefore, we abandoned this algorithm, and we tried some micro-optimizations to the algorithm we
have used so far.
\end{comment}

\hypertarget{micro-optimization-partial-sum}{%
\subsection{Partial sums micro-optimization}\label{micro-optimization-partial-sum}}

When the previous implementations use SSE and AVX instructions to compute the distance between
two data samples, they load from memory a bunch of attributes, they compute the pairwise
difference, they square the result and they accumulate it on a stack-allocated variable, which
requires to horizontally sum all the values in the extended registers.
These operations are repeated until no more attributes are left.

The first micro-optimization we have implemented keeps the partial sums of the distances in an
extended register (which acts as the accumulator stack-allocated variable) and performs the
horizontal sum only once, at the end of the computation.

The new implementation combines all the parallelization strategies we have implemented so far
with this micro-\\optimization.
This implies that the data is still supplied as a unique heap-allocated array.

\begin{tableLayout}{Execution times of the first micro-optimized implementation using AVX (2 and
16 threads tests omitted)}
A4 & 4\ms & \formatNumber{10.174}{s} & \formatNumber{41.862}{s} & \formatNumber{8.887}{s} & 1\m
01\s \\
A8 & 4\ms & \formatNumber{5.820}{s} & \formatNumber{42.804}{s} & \formatNumber{5.592}{s} &
\formatNumber{54.227}{s} \\
A12 & 4\ms & \formatNumber{6.868}{s} & \formatNumber{45.697}{s} & \formatNumber{4.526}{s} &
\formatNumber{57.102}{s} \\
\divisor
G4 & 11\ms & \formatNumber{31.854}{s} & \formatNumber{17.229}{s} & \formatNumber{5.854}{s} & 1\m
05\s \\
G8 & 10\ms & \formatNumber{37.064}{s} & \formatNumber{16.846}{s} & \formatNumber{3.590}{s} &
\formatNumber{57.515}{s} \\
G12 & 9\ms & \formatNumber{37.005}{s} & \formatNumber{17.897}{s} & \formatNumber{3.414}{s} &
\formatNumber{58.330}{s}
\end{tableLayout}

\hypertarget{micro-optimization-no-square-root}{%
\subsection{Square roots micro-optimization}\label{micro-optimization-no-square-root}}

The last micro-optimization we have implemented extends the previous implementation by using the
square of the distances instead of the distances themselves. The computation of the square roots
is applied only at the algorithm and only on the final values of $\lambda$.

Ignoring possible rounding errors, this solution works because the following holds for
non-negative values (as the distances are):
\[
\sqrt{n^2} \geq \sqrt{m^2} \iff n^2 \geq m^2
\]

In the following tables, S5 reports the time taken to compute the square roots.

\begin{tableLayout2}{Execution times of the second micro-optimized implementation using SSE}
A2 & 4\ms & \formatNumber{10.961}{s} & \formatNumber{37.824}{s} & \formatNumber{12.933}{s} &
190$\,\mu$s & 1\m 02\s\\
A4 & 4\ms & \formatNumber{6.641}{s} & \formatNumber{41.826}{s} & \formatNumber{8.989}{s} & 112$\,
\mu$s & \formatNumber{57.466}{s}\\
A8 & 4\ms & \formatNumber{3.903}{s} & \formatNumber{42.693}{s} & \formatNumber{5.592}{s} & 58$\,
\mu$s & \formatNumber{52.199}{s}\\
A12 & 5\ms & \formatNumber{4.603}{s} & \formatNumber{45.701}{s} & \formatNumber{4.549}{s} & 69$\,
\mu$s & \formatNumber{54.864}{s}\\
A16 & 5\ms & \formatNumber{4.067}{s} & \formatNumber{51.38}{s} & \formatNumber{4.222}{s} & 52$\,
\mu$s & \formatNumber{59.340}{s}\\
\divisor
G2 & 9\ms & 1\m 5\s & \formatNumber{15.592}{s} & \formatNumber{9.995}{s} & 113\,$\mu$s & 1\m 30\s\\
G4 & 9\ms & \formatNumber{43.109}{s} & \formatNumber{16.769}{s} & \formatNumber{6.865}{s} & 66$\,
\mu$s & 1\m 07\s\\
G8 & 9\ms & \formatNumber{36.077}{s} & \formatNumber{16.618}{s} & \formatNumber{3.834}{s} & 35$\,
\mu$s & \formatNumber{56.544}{s}\\
G12 & 9\ms & \formatNumber{36.747}{s} & \formatNumber{17.697}{s} & \formatNumber{3.430}{s} &
48$\,\mu$s & \formatNumber{57.890}{s}\\
G16 & 5\ms & \formatNumber{36.383}{s} & \formatNumber{20.554}{s} & \formatNumber{3.100}{s} &
38$\,\mu$s & 1\m 01\s
\end{tableLayout2}

\begin{tableLayout2}{Execution times of the second micro-optimized implementation using AVX}
A2 & 4\ms & \formatNumber{11.439}{s} & \formatNumber{37.881}{s} & \formatNumber{13.146}{s} &
216$\,\mu$s & 1\m 02\s\\
A4 & 4\ms & \formatNumber{7.106}{s} & \formatNumber{42.571}{s} & \formatNumber{8.888}{s} & 115$\,
\mu$s & \formatNumber{58.576}{s}\\
A8 & 4\ms & \formatNumber{4.147}{s} & \formatNumber{42.281}{s} & \formatNumber{5.607}{s} & 61$\,
\mu$s & \formatNumber{52.046}{s}\\
A12 & 5\ms & \formatNumber{5.271}{s} & \formatNumber{44.500}{s} & \formatNumber{4.595}{s} & 71$\,
\mu$s & \formatNumber{54.376}{s}\\
A16 & 5\ms & \formatNumber{4.386}{s} & \formatNumber{50.834}{s} & \formatNumber{4.346}{s} & 52$\,
\mu$s & \formatNumber{59.578}{s}\\
\divisor
G2 & 9\ms & \formatNumber{53.895}{s} & \formatNumber{16.303}{s} & \formatNumber{10.436}{s} &
124$\,\mu$s & 1\m 21\s\\
G4 & 10\ms & \formatNumber{41.312}{s} & \formatNumber{16.961}{s} & \formatNumber{6.453}{s} &
67$\,\mu$s & 1\m 05\s\\
G8 & 8\ms & \formatNumber{37.104}{s} & \formatNumber{16.829}{s} & \formatNumber{3.715}{s} & 35$\,
\mu$s & \formatNumber{57.663}{s}\\
G12 & 8\ms & \formatNumber{37.015}{s} & \formatNumber{17.697}{s} & \formatNumber{3.430}{s} &
47$\,\mu$s & \formatNumber{58.427}{s} \\
G16 & 9\ms & \formatNumber{37.781}{s} & \formatNumber{20.467}{s} & \formatNumber{3.212}{s} &
38$\,\mu$s & 1\m 01\s
\end{tableLayout2}


\hypertarget{sequential-linearized}{
\subsection{A new data structure for the sequential implementation}
\label{sequential-linearized}}

At this point, we asked ourselves if the memory layout we have used so far in the parallel
implementations can also improve the performances of the sequential one.

%\loremTableSequential
\begin{tableLayout}{Execution times of the sequential implementation using a contiguous data
structure}
A & 4\ms & \formatNumber{27.978}{s} & \formatNumber{28.764}{s} & \formatNumber{20.663}{s} & 1\m
17\s \\
\divisor
G & 16\ms & 2\m 24\s & \formatNumber{16.307}{s} & \formatNumber{13.705}{s} & 2\m 54\s
\end{tableLayout}

As we can see, using a unique heap-allocated vector to store the data samples to cluster
drastically improves the performance of the sequential implementation, even without using any
parallelization technique.

Indeed, making all the data samples contiguous in memory greatly improves the use of the cache,
as we observed using the \textit{perf} tool.

\hypertarget{Data layouts comparison}{
\subsection{Data layouts comparison}
\label{data-layout-comparison}}

Finally, we report the results of the tests we have performed on the last parallel implementation
of the clustering algorithm, but supplying the data in the format we have used in the first
implementation, i.e., as a \texttt{std::vector<double *>} -- a vector of heap allocated arrays
each of which holding the attributes of one data sample.

The tables 12 and 13 report the results, where S5 reports the time taken to compute the square
roots.

%\loremTable

\begin{tableLayout2}{Execution times of the second micro-optimized implementation using SSE and
\texttt{std::vector<double*>}}
A2 & 9\ms & \formatNumber{42.708}{s} & \formatNumber{41.007}{s} & \formatNumber{17.475}{s} &
170$\,\mu$s & 1\m 41\s \\
A4 & 6\ms & \formatNumber{34.021}{s} & \formatNumber{42.132}{s} & \formatNumber{9.814}{s} & 97$\,
\mu$s & 1\m 26\s \\
A8 & 6\ms & \formatNumber{29.379}{s} & \formatNumber{42.149}{s} & \formatNumber{6.243}{s} & 51$\,
\mu$s & 1\m 18\s \\
A12 & 6\ms & \formatNumber{29.705}{s} & \formatNumber{43.549}{s} & \formatNumber{5.491}{s} &
72$\,\mu$s & 1\m 18\s \\
A16 & 7\ms & \formatNumber{30.903}{s} & \formatNumber{48.340}{s} & \formatNumber{5.206}{s} &
54$\,\mu$s & 1\m 24\s \\
\divisor
G2 & 9\ms & 2\m 52\s & \formatNumber{17.576}{s} & \formatNumber{10.547}{s} & 118$\,\mu$s & 3\m
20\s \\
G4 & 9\ms & 1\m 47\s & \formatNumber{19.144}{s} & \formatNumber{6.986}{s} & 66$\,\mu$s & 2\m 13\s \\
G8 & 9\ms & 1\m 24\s & \formatNumber{18.963}{s} & \formatNumber{4.404}{s} & 35$\,\mu$s & 1\m 48\s \\
G12 & 10\ms & 1\m 31\s & \formatNumber{20.374}{s} & \formatNumber{4.026}{s} & 49$\,\mu$s & 1\m
56\s \\
G16 & 10\ms & 1\m 31\s & \formatNumber{22.532}{s} & \formatNumber{3.765}{s} & 39$\,\mu$s & 1\m 57\s
\end{tableLayout2}

\begin{tableLayout2}{Execution times of the second micro-optimized implementation using AVX and
\texttt{std::vector<double*>}}
A2 & 7\ms & \formatNumber{33.418}{s} & \formatNumber{39.571}{s} & \formatNumber{15.797}{s} &
181$\,\mu$s & 1\m 29\s \\
A4 & 7\ms & \formatNumber{20.032}{s} & \formatNumber{40.853}{s} & \formatNumber{9.820}{s} & 95$\,
\mu$s & 1\m 11\s \\
A8 & 7\ms & \formatNumber{13.387}{s} & \formatNumber{42.220}{s} & \formatNumber{5.761}{s} & 61$\,
\mu$s & 1\m 01\s \\
A12 & 8\ms & \formatNumber{16.225}{s} & \formatNumber{44.615}{s} & \formatNumber{4.966}{s} &
68$\,\mu$s & 1\m 05\s \\
A16 & 9\ms & \formatNumber{19.212}{s} & \formatNumber{50.916}{s} & \formatNumber{4.934}{s} &
52$\,\mu$s & 1\m 15\s \\
\divisor
G2 & 14\ms & 2\m 27\s & \formatNumber{16.368}{s} & \formatNumber{10.641}{s} & 126$\,\mu$s & 2\m
54\s\\
G4 & 13\ms & 1\m 35\s & \formatNumber{17.435}{s} & \formatNumber{7.007}{s} & 69$\,\mu$s & 1\m
59\s \\
G8 & 13\ms & 1\m 22\s & \formatNumber{17.152}{s} & \formatNumber{4.432}{s} & 35$\,\mu$s & 1\m
44\s \\
G12 & 13\ms & 1\m 30\s & \formatNumber{20.023}{s} & \formatNumber{4.109}{s} & 53$\,\mu$s & 1\m
54\s \\
G16 & 14\ms & 1\m 29\s & \formatNumber{21.576}{s} & \formatNumber{3.801}{s} & 42$\,\mu$s & 1\m 55\s
\end{tableLayout2}

\hypertarget{speed-up}{
\subsection{Speed-up}
\label{speed-up}}

In all the parallel implementations we have used the \textit{OpenMP} library to parallelize the
\texttt{for} loops. We tried a combination different scheduling policies, but the most effective
one is the \texttt{static} policy on all the \texttt{for} loops.

%2.1 - 2.11

When using the \texttt{std::vector<double*>} memory layout, we reached a speed-up of 2.4262 for the
\textit{Accelerometer} dataset and a speed-up of 5.4615 for the \textit{Generated} dataset with
the AVX solution described in \ref{data-layout-comparison} and 8 threads.

Instead, when we consider the contiguous memory layout, we obtained a speed-up of 1.4794 for the
\textit{Accelerometer} dataset with the AVX solution described in
\ref{micro-optimization-no-square-root} and 8 threads, while we obtained a speed-up of 3.0772 for
the \textit{Generated} dataset with the SSE solution described in \ref{data-layout-comparison}
and 8 threads.
% Higher speed-up because of the number of attributes

% Maybe: Are the various implementations effective in improving the performance

%\lipsum[1-2]

\newlength{\graphShift}
\newlength{\axesLineWidth}
\newlength{\gridLineWidth}
\newlength{\graphLineWidth}
\setlength{\graphShift}{30mm}
\setlength{\axesLineWidth}{2pt}
\setlength{\gridLineWidth}{1pt}
\setlength{\graphLineWidth}{2pt}


\definecolor{gridColor}{HTML}{123456}
\definecolor{labelColor}{HTML}{000000}
\definecolor{parallel1Color}{HTML}{587DE5}
\definecolor{parallel2Color}{HTML}{F79B15}
\definecolor{parallel3Color}{HTML}{E8513E}
\definecolor{parallel4Color}{HTML}{72B127}
\definecolor{parallel5Color}{HTML}{D36B06}
\definecolor{parallel6Color}{HTML}{9F47B0}
\definecolor{parallel7Color}{HTML}{7566D0}
\definecolor{parallel8Color}{HTML}{F07629}
\definecolor{parallel9Color}{HTML}{00B3B3}
\definecolor{parallel10Color}{HTML}{17A1DA}
\definecolor{parallel11Color}{HTML}{B9B800}

% 1 = 87
% 5 = 15
% 4 units = 72 mm

% 1 = 87
% 5 = 15
% 2 units = 72 mm


\begin{figure}[H]
\centering
\begin{subfigure}{.47\linewidth}%
\begin{tikzpicture}[scale=0.47]
%\draw (0mm, 0mm) rectangle (100mm, 130mm);
% Horizontal grid
% Total 72 for 1.5 --> 48 for 1 ---> 24 for 0.5
%\draw[gridColor,line width=\gridLineWidth] (10mm, 96mm) -- (95mm, 96mm);
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (95mm, 87mm) -- (10mm, 87mm)
node[labelColor, anchor=east] {2.5};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (95mm, 63mm) -- (10mm, 63mm)
node[labelColor, anchor=east] {2};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (95mm, 39mm) -- (10mm, 39mm)
node[labelColor, anchor=east] {1.5};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (95mm, 15mm) -- (10mm, 15mm)
node[labelColor, anchor=east] {1};
% Vertical grid
% (85-68)/2 = 8.5 mm of margin left and right
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (18.5mm, 95mm) -- (18.5mm, 10mm)
node[labelColor,
anchor=north] {2};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (35.5mm, 95mm) -- (35.5mm, 10mm)
node[labelColor,
anchor=north] {4};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (52.5mm, 95mm) -- (52.5mm, 10mm)
node[labelColor,
anchor=north] {8};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (69.5mm, 95mm) -- (69.5mm, 10mm)
node[labelColor,
anchor=north] {12};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (86.5mm, 95mm) -- (86.5mm, 10mm)
node[labelColor,
anchor=north] {16};
% Lines
\draw[parallel1Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 34.02mm) --
(35.5mm, 46.82mm) --
(52.5mm, 55.80mm) --
(69.5mm, 50.58mm) --
(86.5mm, 37.34mm);

\draw[parallel2Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 38.04mm) --
(35.5mm, 43.39mm) --
(52.5mm, 49.60mm) --
(69.5mm, 46.82mm) --
(86.5mm, 36.65mm);

\draw[parallel3Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 37.34mm) --
(35.5mm, 49.60mm) --
(52.5mm, 56.92mm) --
(69.5mm, 52.59mm) --
(86.5mm, 38.76mm);

\draw[parallel4Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 14.38mm) --
(35.5mm, 19.80mm) --
(52.5mm, 22.16mm) --
(69.5mm, 19.80mm) --
(86.5mm, 13.78mm);

\draw[parallel5Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 11.53mm) --
(35.5mm, 14.38mm) --
(52.5mm, 16.95mm) --
(69.5mm, 16.28mm) --
(86.5mm, 13.20mm);

\draw[parallel6Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 16.95mm) --
(35.5mm, 26.61mm) --
(52.5mm, 35.44mm) --
(69.5mm, 33mm) --
(86.5mm, 26.61mm);

\draw[parallel7Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 19.06mm) --
(35.5mm, 27.59mm) --
(52.5mm, 35.44mm) --
(69.5mm, 31.84mm) --
(86.5mm, 25.67mm);

\draw[parallel8Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 26.61mm) --
(35.5mm, 31.84mm) --
(52.5mm, 38.08mm) --
(69.5mm, 35.44mm) --
(86.5mm, 29.64mm);

\draw[parallel9Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 26.61mm) --
(35.5mm, 30.72mm) --
(52.5mm, 38.08mm) --
(69.5mm, 35.44mm) --
(86.5mm, 29.64mm);

\draw[parallel10Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 37.34mm) --
(35.5mm, 49.06mm) --
(52.5mm, 58.08mm) --
(69.5mm, 58.08mm) --
(86.5mm, 51.57mm);

\draw[parallel11Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 46.82mm) --
(35.5mm, 67.06mm) --
(52.5mm, 83.46mm) --
(69.5mm, 76.29mm) --
(86.5mm, 61.72mm);
% Axes
\draw[line width=\axesLineWidth, yshift=\graphShift] (95mm, 10mm) -- (10mm, 10mm) -- (10mm, 95mm);
\fill[line width=\axesLineWidth, yshift=\graphShift] (7.5mm, 92mm) -- (10mm, 97mm) -- (12.5mm,
92mm) --
cycle;
% Labels
\draw[yshift=\graphShift] (6mm, 100mm) node[labelColor, anchor=north] {$S$};
\draw[yshift=\graphShift] (96mm, 9mm) node[labelColor, anchor=north] {$p$};
% Legend
\fill[parallel1Color] (4mm, 28mm) rectangle (10mm, 22mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.2};
\fill[parallel2Color] (28mm, 28mm) rectangle (34mm, 22mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.3\footnotesize S};
\fill[parallel3Color] (52mm, 28mm) rectangle (58mm, 22mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.3\footnotesize A};
\fill[parallel4Color] (76mm, 28mm) rectangle (82mm, 22mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.4\footnotesize S};

\fill[parallel5Color] (4mm, 18mm) rectangle (10mm, 12mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.4\footnotesize A};
\fill[parallel6Color] (28mm, 18mm) rectangle (34mm, 12mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.6};
\fill[parallel7Color] (52mm, 18mm) rectangle (58mm, 12mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.8};
\fill[parallel8Color] (76mm, 18mm) rectangle (82mm, 12mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.9\footnotesize S};

\fill[parallel9Color] (4mm, 8mm) rectangle (10mm, 2mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.9\footnotesize A};
\fill[parallel10Color] (28mm, 8mm) rectangle (34mm, 2mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.11\footnotesize S};
\fill[parallel11Color] (54mm, 8mm) rectangle (60mm, 2mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.11\footnotesize A};
\end{tikzpicture}
\caption*{Speed-up of the parallel implementations on the \textit{Accelerometer} dataset}%
\end{subfigure}%
%
%
%
%
%
\hspace{5mm}%
%
%
%
%
\begin{subfigure}{.47\linewidth}%
\begin{tikzpicture}[scale=0.47]
%\draw (0mm, 0mm) rectangle (100mm, 130mm);
% Horizontal grid
% Total 81 for 4.5 --> 18 for 1
%\draw[gridColor,line width=\gridLineWidth] (10mm, 96mm) -- (95mm, 96mm);
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (95mm, 87mm) -- (10mm, 87mm)
node[labelColor,
anchor=east] {5};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (95mm, 69mm) -- (10mm, 69mm)
node[labelColor,
anchor=east] {4};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (95mm, 51mm) -- (10mm, 51mm)
node[labelColor,
anchor=east] {3};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (95mm, 33mm) -- (10mm, 33mm)
node[labelColor,
anchor=east] {2};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (95mm, 15mm) -- (10mm, 15mm)
node[labelColor,
anchor=east] {1};
% Vertical grid
% (85-68)/2 = 8.5 mm of margin left and right
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (18.5mm, 95mm) -- (18.5mm, 10mm)
node[labelColor,
anchor=north] {2};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (35.5mm, 95mm) -- (35.5mm, 10mm)
node[labelColor,
anchor=north] {4};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (52.5mm, 95mm) -- (52.5mm, 10mm)
node[labelColor,
anchor=north] {8};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (69.5mm, 95mm) -- (69.5mm, 10mm)
node[labelColor,
anchor=north] {12};
\draw[gridColor,line width=\gridLineWidth, yshift=\graphShift] (86.5mm, 95mm) -- (86.5mm, 10mm)
node[labelColor,
anchor=north] {16};
% Lines
\draw[parallel1Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 33.38mm) --
(35.5mm, 56.10mm) --
(52.5mm, 79.45mm) --
(69.5mm, 72.18mm) --
(86.5mm, 71.09mm);

\draw[parallel2Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 31.08mm) --
(35.5mm, 51.38mm) --
(52.5mm, 72.73mm) --
(69.5mm, 71.09mm) --
(86.5mm, 71.63mm);

\draw[parallel3Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 30.74mm) --
(35.5mm, 51.67mm) --
(52.5mm, 73.87mm) --
(69.5mm, 69mm) --
(86.5mm, 70.03mm);

\draw[parallel4Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 28.32mm) --
(35.5mm, 38.76mm) --
(52.5mm, 43.75mm) --
(69.5mm, 43.06mm) --
(86.5mm, 42.39mm);

\draw[parallel5Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 28.64mm) --
(35.5mm, 37.68mm) --
(52.5mm, 41.74mm) --
(69.5mm, 41.11mm) --
(86.5mm, 38.76mm);

\draw[parallel6Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 29.29mm) --
(35.5mm, 42.39mm) --
(52.5mm, 51mm) --
(69.5mm, 49.20mm) --
(86.5mm, 46.71mm);

\draw[parallel7Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 34.29mm) --
(35.5mm, 45.18mm) --
(52.5mm, 51.95mm) --
(69.5mm, 51mm) --
(86.5mm, 48.34mm);

\draw[parallel8Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 31.80mm) --
(35.5mm, 43.75mm) --
(52.5mm, 52.93mm) --
(69.5mm, 51.95mm) --
(86.5mm, 48.34mm);

\draw[parallel9Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 35.67mm) --
(35.5mm, 45.18mm) --
(52.5mm, 51.95mm) --
(69.5mm, 51mm) --
(86.5mm, 48.34mm);

\draw[parallel10Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 48.12mm) --
(35.5mm, 73.87mm) --
(52.5mm, 91.67mm) --
(69.5mm, 85.14mm) --
(86.5mm, 84.38mm);

\draw[parallel11Color, line width=\graphLineWidth, yshift=\graphShift]
(18.5mm, 55.76mm) --
(35.5mm, 82.92mm) --
(52.5mm, 95.31mm) --
(69.5mm, 86.68mm) --
(86.5mm, 85.9mm);
% Axes
\draw[line width=\axesLineWidth, yshift=\graphShift] (95mm, 10mm) -- (10mm, 10mm) -- (10mm, 95mm);
\fill[line width=\axesLineWidth, yshift=\graphShift] (7.5mm, 92mm) -- (10mm, 97mm) -- (12.5mm,
92mm) --
cycle;
% Labels
\draw[yshift=\graphShift] (6mm, 100mm) node[labelColor, anchor=north] {$S$};
\draw[yshift=\graphShift] (96mm, 9mm) node[labelColor, anchor=north] {$p$};
% Legend
\fill[parallel1Color] (4mm, 28mm) rectangle (10mm, 22mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.2};
\fill[parallel2Color] (28mm, 28mm) rectangle (34mm, 22mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.3\footnotesize S};
\fill[parallel3Color] (52mm, 28mm) rectangle (58mm, 22mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.3\footnotesize A};
\fill[parallel4Color] (76mm, 28mm) rectangle (82mm, 22mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.4\footnotesize S};

\fill[parallel5Color] (4mm, 18mm) rectangle (10mm, 12mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.4\footnotesize A};
\fill[parallel6Color] (28mm, 18mm) rectangle (34mm, 12mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.6};
\fill[parallel7Color] (52mm, 18mm) rectangle (58mm, 12mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.8};
\fill[parallel8Color] (76mm, 18mm) rectangle (82mm, 12mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.9\footnotesize S};

\fill[parallel9Color] (4mm, 8mm) rectangle (10mm, 2mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.9\footnotesize A};
\fill[parallel10Color] (28mm, 8mm) rectangle (34mm, 2mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.11\footnotesize S};
\fill[parallel11Color] (54mm, 8mm) rectangle (60mm, 2mm) node[labelColor, anchor=mid west,
yshift=0.25\baselineskip, xshift=-2pt] {2.11\footnotesize A};
\end{tikzpicture}%
\caption*{Speed-up of the parallel implementations on the \textit{Generated} dataset}%
\end{subfigure}%
\end{figure}



\vspace{-15pt}
\hypertarget{how-to-use-the-library}{
\section{How to use the library}
\label{how-to-use-the-library}}

%    TODO: Requires C++ 20
%TODO: the data samples can have whatever dimension you want, provided that all the samples have
%the same dimension.
%    TODO: Missing specification of which compiler flags we have used (at least -O3 and
%   -march=native)
%TODO: Cache sizes?
%   TODO: Structure used in the tests to hold pi and lambda --> std::vector

We organized the implementations of the clustering algorithms into a library composed of two
main classes, namely the\\
\texttt{SequentialClustering} and the \texttt{ParallelClustering} classes.
The first, defined in the \texttt{SequentialClustering.h} header file provides the sequential
implementation of the clustering algorithm, while the second, defined in the
\texttt{ParallelClustering.h} header file, provides all the parallel implementations of the
clustering algorithm.

All the implementations (sequential and parallel) are able to process data samples with any
number of attributes, provided that all the samples have the same number of attributes.

The \texttt{main-sample.cpp} file in the \texttt{test/src} directory contains an example
illustrating how to use the library.

\hypertarget{parallel-clustering}{%
\subsection{\texttt{ParallelClustering} class}
\label{parallel-clustering}}
This class offers several utility methods and constants allowing the programmer to easily deal
with aligned memory. In particular, the \texttt{computeSseDimension} and
\texttt{computeAvxDimension} static methods allows to compute the number of \texttt{double}
elements each data sample must be compose of, taking into account also possible paddings.

However, the \texttt{cluster} static method is most important one offered by this class. It clusters
the given data samples using the specified distance computation algorithm (see
\ref{distance-computation-algorithms} for the list of available algorithms).
It is specified as a template argument so to compile only the code needed to execute the selected
algorithm.
The method allows also to specify also the number of threads to use in each of the steps that can be
parallelized, namely:
\begin{enumerate}
\item The computation of the distance between two data samples;
\item The operations needed to fix the structure of the dendrogram after a new point is
added, i.e., fixing the representative of all the points whose representative joined a
cluster containing the new data sample (the step \textit{4} of the algorithm);
\item The computation of the square roots of the distances stored in $\lambda$.
\end{enumerate}
Note that the parallelization of such steps can be enabled or disabled at compile time by using the
template parameters of the \texttt{ParallelClustering} class.

\hypertarget{par-data-samples-layout}{
\subsubsection{Data samples memory layout}
\label{par-data-samples-layout}}

The \texttt{cluster} static method allows a certain flexibility in the memory layout of the data
samples. In particular, the method accepts two main organizations:
\begin{enumerate}
\item A contiguous region of memory, where the data samples are stored one after the other.
The method accepts either an iterator iterating over that region, or directly the data
structure holding it. In this case, the \texttt{cluster} method takes care of extracting the
iterator by calling the \texttt{begin} method or, if present, the \texttt{cbegin} one;

\item A data layout organized in two levels.

The first level is merely a container that holds the data samples to cluster (or the iterators
iterating over them). This container is required to be randomly accessible, but it is not
required to be contiguous in memory.

Each element of the second level is a data structure (or an iterator iterating over it) holding a
contiguous region of memory that stores the attributes of one data sample.

For both levels, the \texttt{cluster} method accepts either the iterator over the data structure, or
the data structure itself. In this last case, the method takes care of calling the
\texttt{begin} method, or the \texttt{cbegin} one if present, to obtain an iterator iterating
over the data structure.

\end{enumerate}

\hypertarget{par-pi-lambda-layout}{
\subsubsection{\texorpdfstring{\boldmath$\pi$ and \boldmath$\lambda$}{pi and lambda} memory layouts}
\label{par-pi-lambda-layout}}

The \texttt{cluster} static method allows also a certain flexibility in the memory layout of
$\pi$ and $\lambda$.

In particular, each of them can be any randomly accessible data structure, or an iterator
iterating over it.
In the former case, the method takes care of calling \texttt{begin} method, or the
\texttt{cbegin} one if present, to retrieve the random access iterator iterating over the
specified data structure.

The \texttt{cluster} method assumes the data structures holding $\pi$ and
$\lambda$ to be as big as the number of data samples to cluster.

\hypertarget{distance-computation-algorithms}{
\subsubsection{Distance computation algorithms}
\label{distance-computation-algorithms}}

The \texttt{cluster} stating method allows the programmer to use different algorithms to compute
the distance between two data samples. In particular:
\begin{itemize}
\item \texttt{CLASSICAL}, which computes the Euclidean distances without using any SIMD
instruction;
\item \texttt{SSE} and \texttt{AVX}, which compute the distances using SSE and AVX
instructions respectively;
\item \texttt{SSE\textunderscore OPTIMIZED} and \texttt{AVX\textunderscore OPTIMIZED}, which
compute the distances using
SSE and AVX instructions respectively, and they keep the partial sums in the registers
instead of storing them into a variable (see
\ref{micro-optimization-partial-sum});
\item \texttt{SSE\textunderscore
OPTIMIZED\textunderscore NO\textunderscore SQUARE\textunderscore ROOT} and\\
\texttt{AVX\textunderscore OPTIMIZED\textunderscore NO\textunderscore SQUARE\textunderscore
ROOT}, which act like\\ \texttt{SSE\textunderscore OPTIMIZED} and
\texttt{AVX\textunderscore OPTIMIZED} respectively, but they compute the square of the distances,
without applying the square root operation (see \ref{micro-optimization-no-square-root}).
\end{itemize}

All these constants are defined in the \texttt{DistanceComputers} enumeration, defined in the
\texttt{DistanceComputers.h} header file.

\hypertarget{sequential-clustering}{
\subsection{\texttt{SequentialClustering} class}
\label{sequential-clustering}}

This class provide only one method, the \texttt{cluster} static method, which executes the
sequential implementation of the clustering algorithm on the specified data samples.

\hypertarget{seq-data-samples-layout}{
\subsubsection{Data samples memory layout}
\label{seq-data-samples-layout}}

The \texttt{cluster} static method supports the same data layouts as the \texttt{cluster} method
of the parallel implementation (see \ref{par-data-samples-layout}).

In addition, if the specified data structure (or iterator) is organized in two levels, then this
method does require the first level to be randomly accessible, but it requires only the first
level to be input iterable (or to be an input iterator).

\hypertarget{seq-pi-lambda-layout}{
\subsubsection{\texorpdfstring{\boldmath$\pi$ and \boldmath$\lambda$}{pi and lambda} memory layouts}
\label{seq-pi-lambda-layout}}

The \texttt{cluster} static method supports exactly the same data layouts for both $\pi$
and $\lambda$ as the \texttt{cluster} method
of the parallel implementation (see \ref{par-pi-lambda-layout}).

\hypertarget{timers}{
\subsection{\texttt{Timer} class}
\label{timer}}

If you define the \texttt{TIMERS} macro, both the sequential and parallel implementations of the
clustering algorithm will measure the time taken to execute each step of the algorithm using a
timer.

In particular, each step is measured by a different timer with a specific identifier, where
\texttt{0} measures the time taken to execute all the service operations, \texttt{1} to
\texttt{4} measure the time taken to execute the corresponding steps of the pseudo-code,
and \texttt{5} measures the time taken to compute the square roots of the values in
$\lambda$. This time is measured only for the parallel implementation if the distance
computation algorithm is one of \texttt{SSE\textunderscore
OPTIMIZED\textunderscore NO\textunderscore SQUARE\textunderscore ROOT} or\\
\texttt{AVX\textunderscore OPTIMIZED\textunderscore NO\textunderscore SQUARE\textunderscore ROOT}.

The \texttt{Timer}, defined in the \texttt{Timer.h} header file, offers the \texttt{print} and
\texttt{printTotal} static methods to print to the console the times measured by each timer.





\end{document}
