\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multicol}
\usepackage{geometry}
\usepackage{float}
\usepackage{hyperref}

\geometry{left=1cm,right=1cm,top=2cm,bottom=2cm}

\hypersetup{
  pdftitle={Clustering Parallelization Project},
  pdfauthor={Alessio de Biasi (870288); Jonathan Gobbo (870506)},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Clustering Parallelization Project}
\author{Alessio de Biasi (870288) \and Jonathan Gobbo (870506)}
\date{August 2022}

% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}

\newcommand{\loremTable}{
\begin{table}[H]
    \centering
    \begin{tabular}[H]{ccccccc}
\hline
& s1 & s2 & s3 & s4 & s5 & tot \\
\hline
B 2 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 \\
B 4 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 \\
B 8 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 \\
B 12 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 \\
B 16 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 \\
G 2 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 \\
G 4 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 \\
G 8 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 \\
G 12 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 \\
G 16 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 \\
\hline
\end{tabular}
    \label{tab:my_label}
\end{table}
}

\newcommand{\loremTableSequential}{
\begin{table}[H]
    \centering
    \begin{tabular}[H]{ccccccc}
\hline
& s1 & s2 & s3 & s4 & s5 & tot \\
\hline
B & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 \\
G & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 & 888.88 \\
\hline
\end{tabular}
    \label{tab:my_label}
\end{table}
}

\setlength{\itemsep}{0pt}
\setlength{\parskip}{0pt}

\begin{document}
\twocolumn
\maketitle


\hypertarget{versions}{%
\section{Versions}\label{versions}}

\hypertarget{sequential}{%
\subsection{Sequential}\label{sequential}}

The first version of the algorithm we implemented is the sequential one.
Data is supplied as a
\texttt{std::vector\textless{}double\ *\textgreater{}}, i.e., a vector
of pointers to arrays stored in heap memory. It is a simple
implementation of the pseudo-code of the \emph{SLINK} algorithm as seen
in the slides, and will be used as reference to measure the speed-up
obtained in the other versions. To generalize our code and hide the data
structures used we decided to use iterators.

\loremTableSequential

\hypertarget{distanze-calcolate-in-parallelo}{%
\subsection{Distanze calcolate in
parallelo}\label{distanze-calcolate-in-parallelo}}

This is the first and simplest parallelized version of the algorithm.
Data is supplied in the same way as the sequential one. The computation
of the distances is parallelized by using the \emph{OpenMP} library. The
decision to begin with this is given by the fact that we observed that
stage of the algorithm to be the most expensive in terms of time, and
also the lack of data dependencies.

\loremTable

\hypertarget{sse-avx}{%
\subsection{SSE \& AVX}\label{sse-avx}}

In the second parallel version we implemented the distance computation
code using \emph{SSE} instructions. We deemed using SIMD instructions
useful since the attributes of each point are contiguous in memory and
we have to apply the same sequence of instructions on each attribute.

In the third revision we replaced the SSE instructions with \emph{AVX}
ones, to see if performance would improve. In both cases we had to deal
with memory alignment by adding padding at the end of each sample with
zeroes, but otherwise the data is supplied in the same way.

\loremTable
\loremTable


\hypertarget{distanze-multithread-sse-avx}{%
\subsection{Distanze multithread + SSE \&
AVX}\label{distanze-multithread-sse-avx}}

In the fourth and fifth solutions we combined respectively the
multithreaded distance calculation with SSE first and AVX second, with
the purpose of seeing if these techniques would work together well.

\loremTable

\loremTable

\hypertarget{linearizing-data-arrayone}{%
\subsection{Linearizing data
(arrayone)}\label{linearizing-data-arrayone}}

In this sixth try we modified the previous multithreaded with AVX
solution to work on data which has been linearized, i.e.~a single array
of double values aligned to work with AVX instructions. The purpose of
this test is to see if there are any cache awareness improvements given
by the linearized memory.

\loremTable
\loremTable

\hypertarget{stage-4-parallel}{%
\subsection{Stage 4 parallel}\label{stage-4-parallel}}

This seventh version is based on the fourth one, with the addition of
the multithreaded parallelization of the stage 4 of the algorithm. Once
again we noticed that at this stage there are no data dependencies,
making it trivial to parallelize.

\loremTable

\loremTable

\hypertarget{ottimizzazione-calcolo-distanze-mantenendo-somme-parziali-allinterno-dei-registri}{%
\subsection{Ottimizzazione calcolo distanze mantenendo somme parziali
all'interno dei
registri}\label{ottimizzazione-calcolo-distanze-mantenendo-somme-parziali-allinterno-dei-registri}}

The eighth and ninth solutions aim to optimize the SSE and AVX code of
the distance calculations by avoiding to write partial sums in memory
and keeping them in the registers. It also uses multithreading in both
the distance calculator and the stage 4.

\loremTable

\loremTable

\hypertarget{linearized-calcolo-distanze-ottimizzato}{%
\subsection{Linearized + calcolo distanze
ottimizzato}\label{linearized-calcolo-distanze-ottimizzato}}

The tenth and eleventh algorithms modify the previous couple of
solutions by passing the linearized data instead.

\loremTable

\loremTable

\hypertarget{utilizzo-dei-quadrati-delle-distanze-linearized}{%
\subsection{Utilizzo dei quadrati delle distanze +
linearized}\label{utilizzo-dei-quadrati-delle-distanze-linearized}}

This approach, based on the previous solutions, is an approximation
algorithm in the sense that it computes the square root of the distances
after the stage 4, causing the previous code to perform inequality
checks with the distances squared. This, despite the rounding errors,
should not cause any issue since if \(\sqrt{n^2} \geq \sqrt{m^2}\), then
\(n^2 \geq m^2\).

\loremTable
\loremTable

\hypertarget{sequential-linearized}{%
\subsection{Sequential + linearized}\label{sequential-linearized}}

\loremTableSequential

\hypertarget{failed-attempt}{%
\subsection{Failed attempt}\label{failed-attempt}}

In this attempt we tried to devise a new parallel distance computation
algorithm.

\hypertarget{how-to-use-the-library}{%
\section{How to use the library}\label{how-to-use-the-library}}

The Sequential and Parallel algorithms are provided respectively by the
\texttt{SequentialClustering.h} and \texttt{ParallelClustering.h} header
files.

\hypertarget{sequential-algorithm}{%
\subsection{Sequential Algorithm}\label{sequential-algorithm}}

The sequential \texttt{cluster} function has the following signature:

\begin{verbatim}
template <DistanceComputers C,
      ParallelDataIterator D,
      PiIterator P,
      LambdaIterator L,
      bool S2 = true,
      bool S4 = false,
      bool S5 = false>
static void cluster(const D dataIterator,
                const std::size_t dataSamplesCount,
                const std::size_t dimension,
                const P piIterator,
                const L lambdaIterator,
                const std::size_t distanceComputationThreadsCount = 0,
                const std::size_t stage4ThreadsCount = 0,
                const std::size_t squareRootThreadsCount = 0)
\end{verbatim}


To invoke the sequential clustering algorithm, the following parameters
must be passed to the \texttt{cluster} function:

\begin{itemize}

\item
  \texttt{dataIterator}: a dataset iterator of generic type \texttt{D}
  that must satisfy the concept \texttt{DataIterator}, defined in the
  header file \texttt{Types.h};
\item
  \texttt{dataSamplesCount}: the number of rows in the dataset;
\item
  \texttt{dimension}: the number of columns in the dataset;
\item
  \texttt{piIterator}: an iterator on the \emph{pi} data structure, of
  generic type \texttt{P} satisfying the \texttt{PiIterator} concept;
\item
  \texttt{lambdaIterator}: an iterator on the \emph{lambda} data
  structure, of generic type \texttt{L} satisfying the
  \texttt{LambdaIterator} concept;
\end{itemize}

The \texttt{cluster} function assumes that the data structures
underlying the \texttt{piIterator} and \texttt{lambdaIterator} iterators
are big enough to hold all the values.

\hypertarget{parallel-algorithm}{%
\subsection{Parallel Algorithm}\label{parallel-algorithm}}

The parallel \texttt{cluster} function has the following signature:

\begin{verbatim}
template <DistanceComputers C,
      ParallelDataIterator D,
      PiIterator P,
      LambdaIterator L,
      bool S2 = true,
      bool S4 = false,
      bool S5 = false>
static void cluster(const D dataIterator,
                const std::size_t dataSamplesCount,
                const std::size_t dimension,
                const P piIterator,
                const L lambdaIterator,
                const std::size_t distanceComputationThreadsCount = 0,
                const std::size_t stage4ThreadsCount = 0,
                const std::size_t squareRootThreadsCount = 0)
\end{verbatim}

To invoke the parallel clustering algorithm, the following parameters
must be passed to the \texttt{cluster} function:

\begin{itemize}
\item
  \texttt{dataIterator}: a dataset iterator of generic type \texttt{D}
  that must satisfy the concept \texttt{ParallelDataIterator}, defined
  in the header file \texttt{Types.h}. In contrary to the sequential
  version, this concept requires data to be addressable through the
  \texttt{{[}{]}} operator to allow concurrent data access;
\item
  \texttt{distanceComputationThreadsCount}: defines the number of
  threads used to compute the distances between the points. By default
  it is \(0\), meaning that OpenMP will use all the available CPU
  threads to perform the computation. If \texttt{S2} is false, this
  value is ignored;
\item
  \texttt{stage4ThreadsCount}: defines the number of threads used to
  perform the stage 4 of the clustering algorithm. If \texttt{S4} is
  false, this value is ignored;
\item
  \texttt{squareRootThreadsCount}: defines the number of threads used to
  compute the square roots of the distances. If \texttt{S5} is false, or
  \texttt{C} is not \texttt{SSE\_OPTIMIZED\_NO\_SQUARE\_ROOT} nor
  \texttt{AVX\_OPTIMIZED\_NO\_SQUARE\_ROOT}, then this value is ignored;
\end{itemize}

The parameters \texttt{dataSamplesCount}, \texttt{dimension},
\texttt{piIterator} and \texttt{lambdaIterator} are equivalent to the
sequential version.

Moreover, the following template parameters must be specified:

\begin{itemize}
\item
  \texttt{DistanceComputers}: enumeration that defines which variant of
  the parallel cluster algorithm to be used to compute the distance
  between the points. Its possible values are \texttt{CLASSICAL},
  \texttt{SSE}, \texttt{AVX}, \texttt{SSE\_OPTIMIZED},
  \texttt{AVX\_OPTIMIZED}, \texttt{SSE\_OPTIMIZED\_NO\_SQUARE\_ROOT},
  \texttt{AVX\_OPTIMIZED\_NO\_SQUARE\_ROOT}. Their meaning are described
  in the previous chapter;
\item
  \texttt{S2}: boolean value defaulted to \texttt{true}, indicates
  whether the distance computation stage of the algorithm should be
  parallelized using threads;
\item
  \texttt{S4}: boolean value defaulted to \texttt{false}, indicates
  whether the stage 4 of the algorithm should be parallelized using
  threads;
\item
  \texttt{S5}: boolean value defaulted to \texttt{false}, indicates
  whether the computation of the square roots of the distances should be
  parallelized using threads. Effective only if \texttt{C} is either
  \texttt{SSE\_OPTIMIZED\_NO\_SQUARE\_ROOT} or
  \texttt{AVX\_OPTIMIZED\_NO\_SQUARE\_ROOT}.
\end{itemize}

\end{document}
